% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/backprop.R
\name{backprop}
\alias{backprop}
\title{Backpropagate data on a neural network}
\usage{
backprop(
  nn,
  newdata,
  n_epoch = 100,
  step_size = 0.1,
  lr = 1,
  batch_size = ceiling(nrow(newdata)/10),
  algo = "backprop",
  trace = FALSE
)
}
\arguments{
\item{nn}{neural network}

\item{newdata}{data.frame of the inputs and the outputs}

\item{n_epoch}{integer : number of iterations of backpropagation going
through every data once.}

\item{step_size}{numeric : multiplier of the gradient.}

\item{lr}{numeric : learning rate. new_param = old_param x (1-lr) + lrxbackproped_param}

\item{batch_size}{integer : size of batch of backpropagation.}

\item{algo}{character : convergence algorithm either "backprop" or "rprop+".}

\item{trace}{logical : printing last ran epoch?}
}
\value{
list of neural network (class : nn) and the mean Loss
}
\description{
Backpropagate data on a neural network
}
