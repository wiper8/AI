% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/backprop.R
\name{backprop_policy}
\alias{backprop_policy}
\title{Backpropagate data on a neural network}
\usage{
backprop_policy(policy_nn, critic_nn, newdata, stepmax = 1, step_size = 0.5)
}
\arguments{
\item{policy_nn}{policy neural network.}

\item{critic_nn}{critic neural network.}

\item{newdata}{data.frame of the inputs from policy and the outputs wanted from critic.}

\item{stepmax}{integer : max number of iterations of backpropagation}

\item{step_size}{numeric : multiplier of the gradient.}
}
\value{
list of neural network (class : nn) and the mean Loss
}
\description{
Backpropagate data on a neural network
}
\examples{
backprop_policy(
policy_nn=policy_nn=neuralnetwork(x~a, 1, startweights="zero"),
critic_nn=neuralnetwork(reward~a+x, 1, startweights=list(matrix(c(0, 0.05, -1), ncol=1), matrix(c(-10, 2), ncol=1))),
newdata=data.frame(a=c(6, 12, 0, -5))
)
}
